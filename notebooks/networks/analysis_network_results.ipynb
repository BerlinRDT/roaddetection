{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of network model results\n",
    "To do:\n",
    "* implement, test/check multi-label computations\n",
    "* use threshold at breakeven point to generate labels\n",
    "* write labels to geotiffs to dir data/test/predict_process or so \n",
    "* implement masks for selecting no_img pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from src.data import utils\n",
    "from src.models.data import *\n",
    "from src.models.model import *\n",
    "from src.models.predict_model import *\n",
    "from src.visualization.visualize import *\n",
    "\n",
    "from src.data.utils import get_tile_prefix\n",
    "from src.models.metrics_img import auc_roc\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io as io\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to append\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/media/hh/hd_internal/hh/DSR_Berlin_2018/roaddetection/\")\n",
    "\n",
    "# base directory with data (image tiles) to be analyzed\n",
    "# dir_eval = \"../../data/validate\"\n",
    "dir_eval = \"../../data/train\"\n",
    "# subdirs\n",
    "dir_x = 'sat'\n",
    "dir_y = 'map'\n",
    "\n",
    "# max. number of samples (files) to analyze (predicition takes a long time)\n",
    "max_num_x = 3\n",
    "\n",
    "# number of samples to plot in detail\n",
    "num_x_show = 2\n",
    "\n",
    "# size of images\n",
    "target_size = (512,512)\n",
    "#target_size = (256,256)\n",
    "\n",
    "# path to & filename of model to analyze\n",
    "trained_model_fn = '../../models/models_unet_borneo_and_harz_03_09_16_15.hdf5'\n",
    "\n",
    "# list any custom loss or metric functions of the model here\n",
    "custom_objects = {'auc_roc': auc_roc}\n",
    "\n",
    "# individual samples to be shown: either None, a list of indexes, or any of 'random', 'head_tail'\n",
    "# (head_tail = picked from top and bottom of list according to metric)\n",
    "mode_sample_choice = \"random\"\n",
    "\n",
    "# colormap to be used for prediction scores \n",
    "cmap_yscore = 'gnuplot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load complete model\n",
    "The additional input arg \"custom_objects\" is needed if custom loss or metrics were used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(trained_model_fn, custom_objects=custom_objects)\n",
    "# based on the output of the last layer, find out whether the model is binary or multiclass\n",
    "model_is_binary = model.get_layer(None,-1).output_shape[3] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some constants, preparatory computations & definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_x, num_x = utils.get_list_samplefiles(os.path.join(dir_eval, dir_x))\n",
    "\n",
    "# actual number of files that will be analyzed, given files available\n",
    "num_x_use = min(num_x, max_num_x)\n",
    "\n",
    "# actual number of samples that can be shown, given number of samples to be analyzed\n",
    "num_x_show = np.min([num_x_show, num_x_use])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over files, collecting data & predicitions (takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLASS_DICT = get_class_dict()\n",
    "# number of pixels per image\n",
    "img_size = np.prod(target_size)\n",
    "# preallocate arrays collecting the label (y) values and y scores of all samples\n",
    "arr_y = np.empty(img_size * num_x_use, dtype=np.uint8)\n",
    "arr_yscore = np.empty(img_size * num_x_use, dtype=np.float32)\n",
    "# array collecting the key metric for each sample individually\n",
    "arr_metric = np.empty(num_x_use)\n",
    "\n",
    "for i, fn in enumerate(file_list_x[:num_x_use]):\n",
    "    # read sat image tile\n",
    "    x = io.imread(os.path.join(dir_eval, dir_x, fn))\n",
    "    # -------------------------------------------------------------------------------- \n",
    "    # revise this part if/once non-covered parts of image tiles are labeled as such\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # determine invalid pixels (for now defined as those with a vale of zero\n",
    "    # in the first band). Variable mask could be used to create a masked array,\n",
    "    # but scikit-learn does not support masked arrays\n",
    "    mask = x[:,:,0] == 0;\n",
    "    # scale x\n",
    "    x = x/255.0\n",
    "    # read corresponding label tile\n",
    "    y = io.imread(os.path.join(dir_eval, dir_y, fn))\n",
    "    # set masked values: first, set zeros in label file to 'no road' value...\n",
    "    y[np.logical_and(np.logical_not(mask), np.logical_not(y))] = CLASS_DICT[\"no_road\"]\n",
    "    # then set pixel positions found to not belong to image to 'no_img' value\n",
    "    y[mask] = CLASS_DICT[\"no_img\"]\n",
    "    # if the model used for prediction is a binary one, set any value above no_road to any_road\n",
    "    if model_is_binary:\n",
    "        y[y>CLASS_DICT[\"no_road\"]] = CLASS_DICT[\"any_road\"]\n",
    "    # copy flattened labels in array\n",
    "    arr_y[i*img_size:(i+1)*img_size] = y.ravel()\n",
    "    # predict\n",
    "    print(\"analyzing {0:s} ({1:0.0f} % non-image pixels)...\".format(fn, 100*np.sum(mask)/img_size))\n",
    "    yscore = model.predict(x.reshape((1,) + target_size +(4,)))\n",
    "    # copy flattened prediction in array\n",
    "    arr_yscore[i*img_size:(i+1)*img_size] = yscore.ravel()\n",
    "    # compute and store metric used for sorting\n",
    "    _, _, roc_auc_dict, _, _, pr_auc_dict, _, _, _ = multiclass_roc_pr(y.ravel(), yscore.ravel())\n",
    "\n",
    "    if len(pr_auc_dict) == 0:\n",
    "        arr_metric[i] = None\n",
    "    elif len(pr_auc_dict) == 1:\n",
    "        # binary labels\n",
    "        arr_metric[i] = pr_auc_dict[list(pr_auc_dict.keys())[0]]\n",
    "    else:\n",
    "        # pick average\n",
    "        arr_metric[i] = pr_auc_dict[\"avg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and plot metrics on ensemble of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_dict, \n",
    "tpr_dict,\n",
    "roc_auc_dict, \n",
    "precision_dict, \n",
    "recall_dict,\n",
    "pr_auc_dict,\n",
    "beven_ix_dict,\n",
    "beven_thresh_dict,\n",
    "reduced_class_dict) = multiclass_roc_pr(arr_y, arr_yscore)\n",
    "\n",
    "# set up summary figure\n",
    "fig_sum, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "plot_pr(recall_dict, precision_dict, pr_auc_dict, beven_ix_dict, beven_thresh_dict, axs[0, 0])\n",
    "plot_roc(fpr_dict, tpr_dict, roc_auc_dict, axs[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare index for showing samples\n",
    "samples_ix = utils.gen_sample_index(num_x_use, num_x_show, mode_sample_choice=mode_sample_choice, metric=arr_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ix in samples_ix:\n",
    "    fn = file_list_x[ix]\n",
    "    # read sat image tile\n",
    "    x = io.imread(os.path.join(dir_eval, dir_x, fn))\n",
    "    # retrieve labels\n",
    "    y = arr_y[ix*img_size:(ix+1)*img_size].reshape(target_size)\n",
    "    # retrieve y score (prediction)\n",
    "    yscore = arr_yscore[ix*img_size:(ix+1)*img_size].reshape(target_size)\n",
    "    \n",
    "    fig_sample = show_sample_prediction(x, y, yscore, cmap=cmap_yscore, title=fn)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# halt\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outdated stuff\n",
    "which is not used currently but may come in handy later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick test of multiclass_roc\n",
    "multiclass_roc(np.r_[0, 40, 40, 0, 255, 255, 0, 255], np.empty(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input arguments to Keras' ImageDataGenerator - be sure not to include any image augmentation here!\n",
    "data_gen_args = dict(data_format=\"channels_last\")\n",
    "\n",
    "# batch size for summary stats without visualization (the more, the more efficient, but limited by memory)\n",
    "batch_size = 3\n",
    "\n",
    "\n",
    "# 'steps' input par into evaluate_generator\n",
    "steps =  num_x_use // batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation: only numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up test gen with a batch size as large as possible for efficiency reasons\n",
    "test_gen = trainGenerator(batch_size, eval_dir, img_dir, label_dir,\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)\n",
    "res = model.evaluate_generator(test_gen, steps=steps, workers=1, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run prediction for display of images and more sophisticated evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_gen, steps=steps, workers=1, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[5].reshape(target_size), cmap='gray');\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generator is supposed to yield single images and matching labels, hence batch size = 1\n",
    "#batch1_test_gen = trainGenerator(1, eval_dir, img_dir, label_dir,\n",
    "#                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)\n",
    "# preallocate linear arrays for collecting flattened predicition and label data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
