{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 'baseline' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from keras.layers import merge\n",
    "from src.data import utils\n",
    "from src.models.data import *\n",
    "from src.models.model import *\n",
    "from src.models.predict_model import *\n",
    "from src.data.utils import get_tile_prefix\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import sys\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to append\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/media/hh/hd_internal/hh/DSR_Berlin_2018/roaddetection/\")\n",
    "\n",
    "# base directories with data (image tiles) to be analyzed\n",
    "base_dir = \"../../data\"\n",
    "dirs = []\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validate\")\n",
    "dirs.append(validation_dir)\n",
    "# subdirs\n",
    "dir_x = 'sat'\n",
    "dir_y = 'map'\n",
    "\n",
    "# max. number of samples (files) to analyze\n",
    "max_num_x = 20\n",
    "\n",
    "# ------------- image characteristics -----------------------------\n",
    "# size of tiles\n",
    "target_size = (512,512)\n",
    "\n",
    "\n",
    "#--------------- model ----------------------------------------------------\n",
    "# set to True if a binary model shall be run\n",
    "model_is_binary = True\n",
    "# path to & filename of model to save\n",
    "trained_model_fn = '../../models/RandomForest_binary.pkl'\n",
    "if True:\n",
    "    # set to True if a binary model shall be run\n",
    "    model_is_binary = False\n",
    "    # path to & filename of model to save\n",
    "    trained_model_fn = '../../models/RandomForest_multiclass.pkl'\n",
    "\n",
    "#--------------- training details / hyperparameters -----------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain list and number of available samples (files)\n",
    "file_list_x, num_x = utils.get_list_samplefiles(os.path.join(train_dir, dir_x))\n",
    "\n",
    "# actual number of samples that will be used for training, given samples available and user's choice\n",
    "num_x_use = min(num_x, max_num_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mdl = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=6,\n",
    "    min_samples_leaf=10,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=None,\n",
    "    verbose=1,\n",
    "    warm_start=False,\n",
    "    class_weight=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180419_074323_0c43_3B_0000.tif: (31 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0001.tif: (9 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0002.tif: (16 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0003.tif: (23 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0004.tif: (31 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0005.tif: (38 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0006.tif: (45 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0007.tif: (53 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0008.tif: (60 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0009.tif: (67 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0010.tif: (74 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0011.tif: (21 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0012.tif: (0 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0014.tif: (0 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0015.tif: (0 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0016.tif: (0 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0017.tif: (0 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0018.tif: (0 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0019.tif: (0 % non-image pixels)...\n",
      "20180419_074323_0c43_3B_0020.tif: (0 % non-image pixels)...\n",
      "2 classes present in data\n"
     ]
    }
   ],
   "source": [
    "CLASS_DICT = get_class_dict()\n",
    "# \n",
    "num_features = 4\n",
    "# number of pixels per image\n",
    "img_size = np.prod(target_size)\n",
    "# preallocate arrays collecting features (x) and labels (y) of all samples\n",
    "arr_x = np.empty((img_size * num_x_use, num_features), dtype=np.float32)\n",
    "arr_y = np.empty(img_size * num_x_use, dtype=np.uint8)\n",
    "\n",
    "\n",
    "for i, fn in enumerate(file_list_x[:num_x_use]):\n",
    "    # read sat image tile\n",
    "    x = io.imread(os.path.join(train_dir, dir_x, fn))\n",
    "    # read corresponding label tile\n",
    "    y = io.imread(os.path.join(train_dir, dir_y, fn))  \n",
    "    # refactor labels\n",
    "    y, mask = refactor_labels(x, y, class_dict=CLASS_DICT, model_is_binary=model_is_binary, meta=None)\n",
    "    # scale x\n",
    "    x = x/255.0\n",
    "    print(\"{0:s}: ({1:0.0f} % non-image pixels)...\".format(fn, 100*np.sum(mask)/img_size))\n",
    "    # copy flattened features and labels in arrays\n",
    "    arr_y[i*img_size:(i+1)*img_size] = y.reshape(img_size, order = 'C')\n",
    "    arr_x[i*img_size:(i+1)*img_size,:] =x.reshape((img_size, num_features), order = 'C')\n",
    "    \n",
    "# retain all except no_img values\n",
    "good_ix = arr_y != CLASS_DICT[\"no_img\"]\n",
    "arr_x = arr_x[good_ix, :]\n",
    "arr_y = arr_y[good_ix]\n",
    "print(\"{} classes present in data\".format(len(np.unique(arr_y))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished after 15 s wall clock time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.1s finished\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "mdl.fit(arr_x, arr_y)\n",
    "t2 = time.time()\n",
    "print(\"Model fitting finished after {0:0.0f} s wall clock time\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17824609, 0.19618918, 0.21164163, 0.4139231 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/RandomForest_binary.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "joblib.dump(mdl, trained_model_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hh/anaconda3/envs/geo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "arr_x_plot = arr_x[::100,:]\n",
    "arr_y_plot = arr_y[::100]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ix = arr_y_plot == 40\n",
    "ax.scatter(arr_x_plot[ix,0], arr_x_plot[ix,1], arr_x_plot[ix,3], c=\"gray\", alpha=0.05)  # , c=c, marker=m\n",
    "ix = arr_y_plot == 200\n",
    "ax.scatter(arr_x_plot[ix,0], arr_x_plot[ix,1], arr_x_plot[ix,3], c=\"red\")  # , c=c, marker=m\n",
    "\n",
    "\n",
    "ax.set_xlabel('B')\n",
    "ax.set_ylabel('G')\n",
    "ax.set_zlabel('IR')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
