{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/mnt/hd_internal/hh/projects_DS/road_detection/roaddetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "#from keras.layers import merge\n",
    "from src.models.data import *\n",
    "from src.models.network_models import segnet\n",
    "from src.data.utils import get_tile_prefix\n",
    "from src.models.metrics_img import auc_roc, auc_pr\n",
    "#import rasterio.plot as rioplot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, LambdaCallback\n",
    "from keras.optimizers import *\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and make (if necessary) train/validation/test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = \"../../data/train\"\n",
    "raw_images_path = \"../../data/raw/images\"\n",
    "dirs = []\n",
    "\n",
    "base_dir = \"../../data\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "\n",
    "train_partial_dir = os.path.join(base_dir, \"train_partial\")\n",
    "dirs.append(train_partial_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, \"validate\")\n",
    "dirs.append(validation_dir)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "dirs.append(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data up into train/validation/test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in dirs:\n",
    "    for file_type in [\"sat\", \"map\", \"sat_rgb\"]:\n",
    "        target = os.path.join(directory, file_type)\n",
    "        print(target, \":\", len(os.listdir(target)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (512,512)\n",
    "data_gen_args = dict(\n",
    "                    data_format=\"channels_last\",\n",
    "                    horizontal_flip=True, \n",
    "                    vertical_flip=True\n",
    " )\n",
    "pretrained_model_fn = '../../models/segnet_06_12_24_00.hdf5'\n",
    "pretrained_model_fn = None\n",
    "\n",
    "trained_model_fn = '../../models/SegNet/segnet_test'\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "steps_per_epoch = 280\n",
    "epochs = 50\n",
    "validation_steps = 60\n",
    "\n",
    "optimizer = Adam(lr=1e-4)\n",
    "loss = 'binary_crossentropy'\n",
    "loss_weights = None\n",
    "metrics = ['accuracy', auc_pr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ImageDataGenerators for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = trainGenerator(batch_size,'../../data/train','sat','map',\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)\n",
    "\n",
    "validation_gen = trainGenerator(batch_size,'../../data/validate','sat','map',\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model, compile, show summary, possibly load weights, define callbacks (including checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segnet()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              loss_weights=loss_weights,\n",
    "              metrics=metrics)\n",
    "model.summary()\n",
    "if (pretrained_model_fn):\n",
    "    model.load_weights(pretrained_model_fn)\n",
    "model_checkpoint = ModelCheckpoint(trained_model_fn, monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "#Stop training if loss doesn't improve for 2 consecutive epochs\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_logger():\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "    formatter = logging.Formatter(log_fmt)\n",
    "    fh = logging.FileHandler('../../logs/segnet.log')\n",
    "    fh.setFormatter(formatter)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.addHandler(fh)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "logging_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: logger.info({'epoch': epoch, 'logs': logs})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              callbacks=[model_checkpoint, early_stop, logging_callback],\n",
    "                              validation_data=validation_gen,\n",
    "                              validation_steps=validation_steps\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history[\"acc\"], label=\"acc\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#     plt.plot(history[\"auc_roc\"], label=\"auc_roc\")\n",
    "#     plt.plot(history[\"val_auc_roc\"], label=\"val_auc_roc\")\n",
    "\n",
    "    plt.plot(history[\"auc_pr\"], label=\"auc_pr\")\n",
    "    plt.plot(history[\"val_auc_pr\"], label=\"val_auc_pr\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(\"../../logs/segnet_06_12_24_00.jpg\")\n",
    "    plt.close()\n",
    "\n",
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGene = testGenerator(\"../../data/test/sat\",target_size=(512,512),as_gray=False)\n",
    "n = 0\n",
    "for img, name in testGene:\n",
    "    results = model.predict(img, batch_size=1)\n",
    "    saveResult(\"../../data/test/predict\", results, name)\n",
    "    n += 1\n",
    "    if(n>300):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
