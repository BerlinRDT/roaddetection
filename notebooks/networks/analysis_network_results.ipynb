{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of model results\n",
    "To do:\n",
    "* use threshold at breakeven point to generate labels\n",
    "* write labels to geotiffs to dir data/test/predict_process or so \n",
    "* implement masks for selecting no_img pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from src.data import utils\n",
    "from src.models.data import *\n",
    "from src.models.model import *\n",
    "from src.models.predict_model import *\n",
    "from src.visualization.visualize import *\n",
    "\n",
    "from src.data.utils import get_tile_prefix\n",
    "from src.models.metrics_img import auc_roc, auc_pr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io as io\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to append\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/media/hh/hd_internal/hh/DSR_Berlin_2018/roaddetection/\")\n",
    "\n",
    "# base directory with data (image tiles) to be analyzed\n",
    "dir_eval = \"../../data/test\"\n",
    "# subdirs\n",
    "dir_x = 'sat'\n",
    "dir_y = 'map'\n",
    "\n",
    "# image size in pixels\n",
    "target_size = (512, 512)\n",
    "\n",
    "# max. number of samples (files) to analyze (predicition takes a long time)\n",
    "max_num_x = 8\n",
    "\n",
    "# ------------- selection of samples to plot in detail -----------------------------\n",
    "if True:\n",
    "    # set *number* of samples (files) to analyze in detail and choose among\n",
    "    # 'random' and 'head_tail'\n",
    "    num_x_show = 20\n",
    "    mode_sample_choice = \"random\"\n",
    "else:\n",
    "    # inverse: select specific samples (these MUST be within the set of files analyzed)\n",
    "    file_list_selected = [\"20170815_005030_0c0b_3B_0072.tif\"]\n",
    "    num_x_show = len(file_list_selected)\n",
    "    mode_sample_choice = None\n",
    "\n",
    "# ----------------- selection of model to analyze -----------------------------\n",
    "if True:\n",
    "    # path to & filename of model to analyze\n",
    "    trained_model_fn = '../../models/models_unet_borneo_and_harz_05_09_09_00.hdf5'\n",
    "    #trained_model_fn = '../../models/models_segnet_06_12_24_00.hdf5'\n",
    "    # framework underlying model\n",
    "    type_model = 'keras'\n",
    "else:\n",
    "    trained_model_fn = '../../models/RandomForest_binary.pkl'\n",
    "    trained_model_fn = '../../models/RandomForest_multiclass.pkl'\n",
    "    # framework underlying model\n",
    "    type_model = 'scikit'\n",
    "\n",
    "# Keras models: list any custom loss or metric functions of the model here\n",
    "custom_objects = {'auc_pr': auc_pr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_model == \"keras\":\n",
    "    # The additional input arg \"custom_objects\" is needed if custom loss or metrics were used in the model\n",
    "    model = load_model(trained_model_fn, custom_objects=custom_objects)\n",
    "    # based on the output of the last layer, find out whether the model is binary or multiclass\n",
    "    model_is_binary = model.get_layer(None,-1).output_shape[3] == 1\n",
    "    num_classes = max(2, model.get_layer(None,-1).output_shape[3])\n",
    "    # infer width, height and number of features (= bands in satellite images) from input layer\n",
    "    input_layer = model.get_layer(None,0).output_shape\n",
    "    # size of images\n",
    "    sz = input_layer[1:3]\n",
    "    num_features = input_layer[3]\n",
    "    assert(sz == target_size), \"nonmatching image tile sizes\"\n",
    "elif type_model == \"scikit\":\n",
    "    model = joblib.load(trained_model_fn)\n",
    "    model_is_binary = model.n_classes_ == 2\n",
    "    num_classes = model.n_classes_\n",
    "    num_features = model.n_features_    \n",
    "\n",
    "print(\"{0:d} features, {1:d} classes\".format(num_features, num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preparatory computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain list and number of available samples (files)\n",
    "file_list_x, num_x = utils.get_list_samplefiles(os.path.join(dir_eval, dir_x))\n",
    "\n",
    "# actual number of samples that will be analyzed, given samples available and user's choice\n",
    "num_x_use = min(num_x, max_num_x)\n",
    "\n",
    "# actual number of samples to be *plotted*, given number of samples to be analyzed\n",
    "num_x_show = min(num_x_show, num_x_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over files, collecting data & predicitions (takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************************************************************************************\n",
    "# CLASS_DICT is central to everything that follows: it maps values in the label files to classes\n",
    "# (no road, paved road, etc.) and also defines new classes (no_img) which are needed\n",
    "# for evaluation metrics. If the values in this dict do not match the label values used during\n",
    "# training, the code will not work or produce nonsense.\n",
    "# **********************************************************************************************\n",
    "CLASS_DICT = get_class_dict(\"all_legal\")\n",
    "\n",
    "# similarly, CLASS_PLOT_PROP defines colors for the different classes\n",
    "CLASS_PLOT_PROP = get_class_plot_prop()\n",
    "\n",
    "# number of pixels per image\n",
    "img_size = np.prod(target_size)\n",
    "\n",
    "# if it is a binary model, the score prediction matrix is 2D, otherwise it has as many layers \n",
    "# (or slices, if you want) as there are classes\n",
    "if model_is_binary:\n",
    "    dim_yscore = 1\n",
    "    class_dict = get_class_dict(\"binary\")\n",
    "    # the following lines are needed to extract the correct column out of the prediction score \n",
    "    # from a Scikit-learn model\n",
    "    tmp_dict = class_dict.copy()\n",
    "    del tmp_dict[\"no_img\"]\n",
    "    yscore_ix = get_sorted_key_index(\"any_road\", tmp_dict)\n",
    "else:\n",
    "    dim_yscore = num_classes\n",
    "    class_dict = get_class_dict(\"multiclass\")\n",
    "\n",
    "\n",
    "# preallocate arrays collecting the label (y) values and y scores of all \n",
    "# all pixels of all tiles\n",
    "arr_y = np.empty((img_size * num_x_use, 1), dtype=np.uint8)\n",
    "arr_yscore = np.empty((img_size * num_x_use, dim_yscore), dtype=np.float32)\n",
    "\n",
    "# array collecting the key metric for each sample (image tile) individually; \n",
    "# useful for a sorted display of individual tiles\n",
    "arr_metric = np.empty(num_x_use)\n",
    "\n",
    "# loop over tiles up to num_x_use)\n",
    "for i, fn in enumerate(file_list_x[:num_x_use]):\n",
    "    # read sat image tile\n",
    "    x = io.imread(os.path.join(dir_eval, dir_x, fn))\n",
    "    # read corresponding label tile\n",
    "    y = io.imread(os.path.join(dir_eval, dir_y, fn))\n",
    "    # refactor labels according to model\n",
    "    y, mask = refactor_labels(x, y, class_dict=CLASS_DICT, model_is_binary=model_is_binary, meta=None)\n",
    "    # scale x\n",
    "    x = x/255.0\n",
    "    # copy reshaped labels in array\n",
    "    y_reshaped = y.reshape((img_size, 1))\n",
    "    arr_y[i*img_size:(i+1)*img_size,:] = y_reshaped\n",
    "    # predict\n",
    "    print(\"analyzing {0:s} ({1:0.0f} % non-image pixels)...\".format(fn, 100*np.sum(mask)/img_size))\n",
    "    if type_model == \"keras\":\n",
    "        # in the case of a binary classification, yscore is a (target_size) array (no third dim)\n",
    "        # in the case of multiclass classification, yscore is a (target_size) by (num_classes) array\n",
    "        yscore = model.predict(x.reshape((1,) + target_size +(4,)))\n",
    "        # reshape for storage and analysis\n",
    "        yscore_reshaped = yscore.reshape((img_size, dim_yscore), order = 'C')\n",
    "    elif type_model == \"scikit\":\n",
    "        # yscore is always a (img_size) by (num_classes) array\n",
    "        yscore = model.predict_proba(x.reshape((img_size, num_features), order = 'C'))\n",
    "        if model_is_binary:\n",
    "            # in contrast to keras' .predict most of scikit-learn's predict_proba methods put out one column per class\n",
    "            # also for binarry classification, so pick only one layer: in a binary classification, p(class 1) = 1-p(class 2)\n",
    "            yscore_reshaped = yscore[:,yscore_ix].reshape((img_size, dim_yscore))\n",
    "        else:\n",
    "            yscore_reshaped = yscore\n",
    "    # copy reshaped prediction in array\n",
    "    arr_yscore[i*img_size:(i+1)*img_size,:] = yscore_reshaped\n",
    "    # compute and store metric used for sorting\n",
    "    _, _, roc_auc_dict, _, _, pr_auc_dict, _, _, _ = multiclass_roc_pr(y_reshaped, yscore_reshaped, class_dict=class_dict)\n",
    "\n",
    "    if len(pr_auc_dict) == 0:\n",
    "        arr_metric[i] = None\n",
    "    elif len(pr_auc_dict) == 1:\n",
    "        # binary labels\n",
    "        arr_metric[i] = pr_auc_dict[list(pr_auc_dict.keys())[0]]\n",
    "    else:\n",
    "        # pick score of union of roads\n",
    "        arr_metric[i] = pr_auc_dict[\"any_road\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and plot metrics on ensemble of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_dict, \n",
    "tpr_dict,\n",
    "roc_auc_dict, \n",
    "precision_dict, \n",
    "recall_dict,\n",
    "pr_auc_dict,\n",
    "beven_ix_dict,\n",
    "beven_thresh_dict,\n",
    "reduced_class_dict) = multiclass_roc_pr(arr_y, arr_yscore, class_dict=class_dict)\n",
    "\n",
    "# set up summary figure\n",
    "fig_sum, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "plot_pr(recall_dict, precision_dict, pr_auc_dict, beven_ix_dict, beven_thresh_dict, axs[0, 0])\n",
    "plot_roc(fpr_dict, tpr_dict, roc_auc_dict, axs[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare index for showing samples\n",
    "if mode_sample_choice is None:\n",
    "    samples_ix = [ix for ix, fn in enumerate(file_list_x[:num_x_use]) if fn in file_list_selected]\n",
    "    if not len(samples_ix):\n",
    "        raise Exception(\"none of the tiles selected for individual plotting is among the tiles analyzed\")\n",
    "else:\n",
    "    samples_ix = utils.gen_sample_index(num_x_use, num_x_show, mode_sample_choice=mode_sample_choice, metric=arr_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ix in samples_ix:\n",
    "    fn = file_list_x[ix]\n",
    "    # read sat image tile\n",
    "    x = io.imread(os.path.join(dir_eval, dir_x, fn))\n",
    "    # retrieve true labels\n",
    "    y = arr_y[ix*img_size:(ix+1)*img_size].reshape(target_size + (1,), order = 'C')\n",
    "    # retrieve y score (prediction)\n",
    "    yscore = arr_yscore[ix*img_size:(ix+1)*img_size, :].reshape(target_size + (dim_yscore,), order = 'C')\n",
    "\n",
    "    # §§§generate predicted labels from yscore using threshold at breakeven point\n",
    "    #beven_thresh_dict\n",
    "    #get_sorted_key_index('no_road', reduced_class_dict)\n",
    "    ypred = predict_labels(yscore, beven_thresh_dict, reduced_class_dict)\n",
    "\n",
    "    # show summary plot\n",
    "    fig_sample = show_sample_prediction(x, y, yscore, ypred, class_dict, title=fn)    \n",
    "    \n",
    "    if not model_is_binary:\n",
    "        # convert true labels to rgb \n",
    "        \n",
    "        y_rgb = grayscale_to_rgb(y, CLASS_PLOT_PROP, class_dict)\n",
    "    \n",
    "        # §§§ convert predicted labels to rgb\n",
    "        ypred_rgb = grayscale_to_rgb(ypred, CLASS_PLOT_PROP, class_dict)\n",
    "        \n",
    "        # §§ save both true and predicted labels to rgb file\n",
    "    else:\n",
    "        # save only predicted labels to file\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# halt\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outdated stuff\n",
    "which is not used currently but may come in handy later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick test of multiclass_roc\n",
    "multiclass_roc(np.r_[0, 40, 40, 0, 255, 255, 0, 255], np.empty(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input arguments to Keras' ImageDataGenerator - be sure not to include any image augmentation here!\n",
    "data_gen_args = dict(data_format=\"channels_last\")\n",
    "\n",
    "# batch size for summary stats without visualization (the more, the more efficient, but limited by memory)\n",
    "batch_size = 3\n",
    "\n",
    "\n",
    "# 'steps' input par into evaluate_generator\n",
    "steps =  num_x_use // batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation: only numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up test gen with a batch size as large as possible for efficiency reasons\n",
    "test_gen = trainGenerator(batch_size, eval_dir, img_dir, label_dir,\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)\n",
    "res = model.evaluate_generator(test_gen, steps=steps, workers=1, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run prediction for display of images and more sophisticated evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_gen, steps=steps, workers=1, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[5].reshape(target_size), cmap='gray');\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generator is supposed to yield single images and matching labels, hence batch size = 1\n",
    "#batch1_test_gen = trainGenerator(1, eval_dir, img_dir, label_dir,\n",
    "#                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)\n",
    "# preallocate linear arrays for collecting flattened predicition and label data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
