{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "#from keras.layers import merge\n",
    "from src.models.data import *\n",
    "from src.models.model import *\n",
    "from src.data.utils import get_tile_prefix\n",
    "from src.models.metrics_img import auc_roc\n",
    "#import rasterio.plot as rioplot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to append\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/media/hh/hd_internal/hh/DSR_Berlin_2018/roaddetection/\")\n",
    "\n",
    "# ------------- image characteristics and augmentation -----------------------------\n",
    "# size of tiles\n",
    "target_size = (512,512)\n",
    "# input arguments to Keras' ImageDataGenerator\n",
    "data_gen_args = dict(\n",
    "                    data_format=\"channels_last\",\n",
    "                    horizontal_flip=True, \n",
    "                    vertical_flip=True\n",
    " )\n",
    "# if True, image tiles will be split up into training/validation/test sets\n",
    "# only required after a fresh 'make data'\n",
    "do_data_split = False\n",
    "# directory into which to place *training* images from ImageDataGenerator for inspection;\n",
    "# default should be None because this slows things down\n",
    "imgdatagen_dir = None\n",
    "#imgdatagen_dir = '../../data/imgdatagenerator'\n",
    "\n",
    "#--------------- network weights ----------------------------------------------------\n",
    "# path to & filename of pre-trained model to use - set to None if you want to start from scratch\n",
    "pretrained_model_fn = \"../../models/unet_membrane_analytic_27_08_14_55.hdf5\"\n",
    "#pretrained_model_fn = None\n",
    "\n",
    "# path to & filename of model to save\n",
    "trained_model_fn = '../../models/unet_membrane_analytic_.hdf5'\n",
    "\n",
    "#--------------- training details / hyperparameters -----------------------------------\n",
    "# batch size\n",
    "batch_size = 2\n",
    "# steps per epoch, should correspond to [number of training images] / batch size\n",
    "steps_per_epoch = 100\n",
    "# number of epochs\n",
    "epochs = 15\n",
    "# number of steps on validation set\n",
    "validation_steps = 20\n",
    "# self-explanatory variables:\n",
    "optimizer = Adam(lr=1e-4)\n",
    "loss = 'binary_crossentropy'\n",
    "loss_weights = None\n",
    "metrics = ['accuracy', auc_roc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and make (if necessary) train/validation/test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = \"../../data/train\"\n",
    "raw_images_path = \"../../data/raw/images\"\n",
    "dirs = []\n",
    "\n",
    "base_dir = \"../../data\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validate\")\n",
    "dirs.append(validation_dir)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "dirs.append(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data up into train/validation/test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_data_split:\n",
    "    def should_make_tiles_from(r_analytic_name):\n",
    "        is_analytic_tif = r_analytic_name.endswith(\n",
    "            ('AnalyticMS.tif', 'AnalyticMS_SR.tif', 'AnalyticMS.tiff', 'AnalyticMS_SR.tiff')\n",
    "        )\n",
    "        return is_analytic_tif \n",
    "\n",
    "    file_prefixes = [ get_tile_prefix(r_analytic.name) \n",
    "                      for r_analytic in Path(raw_images_path).iterdir()  \n",
    "                        if  should_make_tiles_from(r_analytic.name)\n",
    "                    ]\n",
    "    print(file_prefixes)\n",
    "\n",
    "    # move files to validation dir\n",
    "    validation_fnames = [\"{0:s}_{1:04d}.tif\".format(prefix, i) for i in range(1,10) for prefix in file_prefixes]\n",
    "    for fname in validation_fnames:\n",
    "        for file_type in [\"sat\", \"map\", \"sat_rgb\"]:\n",
    "            src = os.path.join(train_dir, file_type, fname)\n",
    "            dest = os.path.join(validation_dir, file_type, fname)\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "    # move files to test dir\n",
    "    test_fnames = [\"{0:s}_{1:04d}.tif\".format(prefix, i) for i in range(40,60) for prefix in file_prefixes]\n",
    "    for fname in test_fnames:\n",
    "        for file_type in [\"sat\", \"map\", \"sat_rgb\"]:\n",
    "            src = os.path.join(train_dir, file_type, fname)\n",
    "            dest = os.path.join(test_dir, file_type, fname)\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "    # print overview\n",
    "    for directory in dirs:\n",
    "        for file_type in [\"sat\", \"map\", \"sat_rgb\"]:\n",
    "            target = os.path.join(directory, file_type)\n",
    "            print(target, \":\", len(os.listdir(target)))\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ImageDataGenerators for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = trainGenerator(batch_size,'../../data/train','sat','map',\n",
    "                        data_gen_args, save_to_dir = imgdatagen_dir, image_color_mode=\"rgba\", target_size=target_size)\n",
    "\n",
    "validation_gen = trainGenerator(batch_size,'../../data/validate','sat','map',\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model, compile, show summary, possibly load weights, define callbacks (including checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              loss_weights=loss_weights,\n",
    "              metrics=metrics)\n",
    "model.summary()\n",
    "if (pretrained_model_fn):\n",
    "    model.load_weights(pretrained_model_fn)\n",
    "model_checkpoint = ModelCheckpoint(trained_model_fn, monitor='loss',verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              callbacks=[model_checkpoint],\n",
    "                              validation_data=validation_gen,\n",
    "                              validation_steps=validation_steps\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history[\"acc\"], label=\"acc\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(history[\"auc_roc\"], label=\"auc_roc\")\n",
    "    plt.plot(history[\"val_auc_roc\"], label=\"val_auc_roc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_history(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
