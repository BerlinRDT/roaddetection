{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/media/hh/hd_internal/hh/DSR_Berlin_2018/roaddetection/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from keras.layers import merge\n",
    "from src.models.data import *\n",
    "from src.models.segnet import *\n",
    "from src.data.utils import get_tile_prefix\n",
    "from src.models.metrics_img import auc_roc, auc_pr\n",
    "#import rasterio.plot as rioplot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, LambdaCallback\n",
    "from keras.optimizers import *\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and make (if necessary) train/validation/test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = \"../../data/train\"\n",
    "raw_images_path = \"../../data/raw/images\"\n",
    "dirs = []\n",
    "\n",
    "base_dir = \"../../data\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "\n",
    "train_partial_dir = os.path.join(base_dir, \"train_partial\")\n",
    "dirs.append(train_partial_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, \"validate\")\n",
    "dirs.append(validation_dir)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "dirs.append(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data up into train/validation/test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/train/sat : 1372\n",
      "../../data/train/map : 1372\n",
      "../../data/train/sat_rgb : 1372\n",
      "../../data/train_partial/sat : 0\n",
      "../../data/train_partial/map : 0\n",
      "../../data/train_partial/sat_rgb : 0\n",
      "../../data/validate/sat : 280\n",
      "../../data/validate/map : 280\n",
      "../../data/validate/sat_rgb : 280\n",
      "../../data/test/sat : 276\n",
      "../../data/test/map : 276\n",
      "../../data/test/sat_rgb : 276\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "for directory in dirs:\n",
    "    for file_type in [\"sat\", \"map\", \"sat_rgb\"]:\n",
    "        target = os.path.join(directory, file_type)\n",
    "        print(target, \":\", len(os.listdir(target)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (512,512)\n",
    "data_gen_args = dict(\n",
    "                    data_format=\"channels_last\",\n",
    "                    horizontal_flip=True, \n",
    "                    vertical_flip=True\n",
    " )\n",
    "pretrained_model_fn = None\n",
    "\n",
    "trained_model_fn = '../../models/segnet_06_12_24_00.hdf5'\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "steps_per_epoch = 280\n",
    "epochs = 10\n",
    "validation_steps = 60\n",
    "\n",
    "optimizer = Adam(lr=1e-4)\n",
    "loss = 'binary_crossentropy'\n",
    "loss_weights = None\n",
    "metrics = ['accuracy', auc_pr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ImageDataGenerators for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = trainGenerator(batch_size,'../../data/train','sat','map',\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)\n",
    "\n",
    "validation_gen = trainGenerator(batch_size,'../../data/validate','sat','map',\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model, compile, show summary, possibly load weights, define callbacks (including checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, activation=\"relu\", padding=\"valid\")`\n",
      "  conv1 = Conv2D(filter_size, kernel, activation='relu', border_mode='valid')(padding1)\n",
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, 3, activation=\"relu\", padding=\"valid\")`\n",
      "  conv2 = Conv2D(256, kernel, activation='relu', border_mode='valid')(padding2)\n",
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, 3, activation=\"relu\", padding=\"valid\")`\n",
      "  conv3 = Conv2D(512, kernel, activation='relu', border_mode='valid')(padding3)\n",
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, 3, padding=\"valid\")`\n",
      "  conv4 = Conv2D(512, kernel, border_mode='valid')(padding4)\n",
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, 3, padding=\"valid\")`\n",
      "  conv5 = Conv2D(256, kernel, border_mode='valid')(padding5)\n",
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"valid\")`\n",
      "  conv6 = Conv2D(128, kernel, border_mode='valid')(padding6)\n",
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"valid\")`\n",
      "  conv7 = Conv2D(filter_size, kernel, border_mode='valid')(padding7)\n",
      "/Users/kprakash/Projects/roaddetection/src/models/segnet.py:54: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input=inputs, output=conv8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 4)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 514, 514, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 512, 512, 64)      2368      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512, 512, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 258, 258, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 256)     147712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 256, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 130, 130, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 128, 512)     2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 66, 66, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 512)       2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 130, 130, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 256)     1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 256, 256, 256)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 258, 258, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 256, 256, 128)     295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256, 256, 128)     512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 512, 512, 128)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 514, 514, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 512, 512, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512, 512, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 512, 512, 1)       65        \n",
      "=================================================================\n",
      "Total params: 5,246,017\n",
      "Trainable params: 5,242,433\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = segnet()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              loss_weights=loss_weights,\n",
    "              metrics=metrics)\n",
    "model.summary()\n",
    "if (pretrained_model_fn):\n",
    "    model.load_weights(pretrained_model_fn)\n",
    "model_checkpoint = ModelCheckpoint(trained_model_fn, monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "#Stop training if loss doesn't improve for 2 consecutive epochs\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_logger():\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "    formatter = logging.Formatter(log_fmt)\n",
    "    fh = logging.FileHandler('../../logs/segnet.log')\n",
    "    fh.setFormatter(formatter)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.addHandler(fh)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "logging_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: logger.info({'epoch': epoch, 'logs': logs})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Found 280 images belonging to 1 classes.\n",
      "Found 1372 images belonging to 1 classes.\n",
      "Found 280 images belonging to 1 classes.\n",
      "Found 1372 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              callbacks=[model_checkpoint, early_stop, logging_callback],\n",
    "                              validation_data=validation_gen,\n",
    "                              validation_steps=validation_steps\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history[\"acc\"], label=\"acc\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#     plt.plot(history[\"auc_roc\"], label=\"auc_roc\")\n",
    "#     plt.plot(history[\"val_auc_roc\"], label=\"val_auc_roc\")\n",
    "\n",
    "    plt.plot(history[\"auc_pr\"], label=\"auc_pr\")\n",
    "    plt.plot(history[\"val_auc_pr\"], label=\"val_auc_pr\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(\"../../logs/unet_borneo_and_harz_05_09_11_11.jpg\")\n",
    "    plt.close()\n",
    "\n",
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testGene = testGenerator(\"../../data/test/sat\",target_size=(512,512),as_gray=False)\n",
    "n = 0\n",
    "for img, name in testGene:\n",
    "    results = model.predict(img, batch_size=1)\n",
    "    saveResult(\"../../data/test/predict\", results, name)\n",
    "    n += 1\n",
    "    if(n>300):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
