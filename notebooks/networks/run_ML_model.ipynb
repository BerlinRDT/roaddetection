{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from keras.layers import merge\n",
    "from src.data import utils\n",
    "from src.models.data import *\n",
    "from src.models.model import *\n",
    "from src.models.predict_model import *\n",
    "from src.data.utils import get_tile_prefix\n",
    "\n",
    "#from rasterio.plot import show, reshape_as_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import signal\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import sys\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to append\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/media/hh/hd_internal/hh/DSR_Berlin_2018/roaddetection/\")\n",
    "\n",
    "# base directories with data (image tiles) to be analyzed\n",
    "base_dir = \"../../data\"\n",
    "dirs = []\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "train_partial_dir = os.path.join(base_dir, \"special\")\n",
    "dirs.append(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validate\")\n",
    "dirs.append(validation_dir)\n",
    "# subdirs\n",
    "dir_x = 'sat'\n",
    "dir_y = 'map'\n",
    "\n",
    "# max. number of samples (files) to analyze\n",
    "max_num_x = 5\n",
    "\n",
    "# ------------- image characteristics -----------------------------\n",
    "# size of tiles\n",
    "target_size = (512,512)\n",
    "\n",
    "\n",
    "#--------------- model ----------------------------------------------------\n",
    "# set to True if a binary model shall be run\n",
    "model_is_binary = True\n",
    "# path to & filename of model to save\n",
    "trained_model_fn = '../../models/RandomForest_binary.pkl'\n",
    "if False:\n",
    "    # set to True if a binary model shall be run\n",
    "    model_is_binary = False\n",
    "    # path to & filename of model to save\n",
    "    trained_model_fn = '../../models/RandomForest_multiclass.pkl'\n",
    "\n",
    "#--------------- training details / hyperparameters -----------------------------------\n",
    "\n",
    "# graphics defaults\n",
    "figsize = (20,12)\n",
    "plt.rcParams[\"figure.figsize\"] = figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain list and number of available samples (files)\n",
    "file_list_x, num_x = utils.get_list_samplefiles(os.path.join(train_dir, dir_x))\n",
    "\n",
    "# actual number of samples that will be used for training, given samples available and user's choice\n",
    "num_x_use = min(num_x, max_num_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180419_074325_0c43_3B_0014.tif: (0 % non-image pixels)...\n",
      "20180419_074325_0c43_3B_0015.tif: (0 % non-image pixels)...\n",
      "20180419_074325_0c43_3B_0017.tif: (0 % non-image pixels)...\n",
      "20180419_074325_0c43_3B_0018.tif: (0 % non-image pixels)...\n",
      "20180419_074325_0c43_3B_0019.tif: (0 % non-image pixels)...\n",
      "2 classes present in data\n"
     ]
    }
   ],
   "source": [
    "CLASS_DICT = get_class_dict()\n",
    "# set up list of functions producing matrices to be used in sequence for convolutional feature engineering\n",
    "conv_matrix_fun = [conv_matrix_inhibsurround, \n",
    "                  conv_matrix_horizontalbar, \n",
    "                  conv_matrix_verticalbar,\n",
    "                  conv_matrix_diag_ullr,\n",
    "                  conv_matrix_diag_llur]\n",
    "\n",
    "conv_matrix_fun = [conv_matrix_inhibsurround]\n",
    "\n",
    "# number of features is the original number of bands plus the convolutions defined above\n",
    "num_features = 4 + len(conv_matrix_fun)\n",
    "# number of pixels per image\n",
    "img_size = np.prod(target_size)\n",
    "# preallocate arrays collecting features (x) and labels (y) of all samples\n",
    "arr_x = np.empty((img_size * num_x_use, num_features), dtype=np.float32)\n",
    "arr_y = np.empty(img_size * num_x_use, dtype=np.uint8)\n",
    "\n",
    "for i, fn in enumerate(file_list_x[:num_x_use]):\n",
    "    # read sat image tile\n",
    "    x = io.imread(os.path.join(train_dir, dir_x, fn))\n",
    "    # feature engineering\n",
    "    x_f = feature_eng_conv(x, conv_matrix_fun, collapse_bands=True)\n",
    "    # read corresponding label tile\n",
    "    y = io.imread(os.path.join(train_dir, dir_y, fn))  \n",
    "    # refactor labels\n",
    "    y, mask = refactor_labels(x, y, class_dict=CLASS_DICT, model_is_binary=model_is_binary, meta=None)\n",
    "    # scale x\n",
    "    x = x/255.0\n",
    "    # now append new features to x\n",
    "    x = np.append(x, x_f, axis=2)\n",
    "    print(\"{0:s}: ({1:0.0f} % non-image pixels)...\".format(fn, 100*np.sum(mask)/img_size))\n",
    "    # copy flattened features and labels in arrays\n",
    "    arr_y[i*img_size:(i+1)*img_size] = y.reshape(img_size, order = 'C')\n",
    "    arr_x[i*img_size:(i+1)*img_size,:] =x.reshape((img_size, num_features), order = 'C')\n",
    "    \n",
    "# retain all except no_img values\n",
    "good_ix = arr_y != CLASS_DICT[\"no_img\"]\n",
    "arr_x = arr_x[good_ix, :]\n",
    "arr_y = arr_y[good_ix]\n",
    "print(\"{} classes present in data\".format(len(np.unique(arr_y))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = RandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    criterion='gini',\n",
    "    max_depth=8,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=50,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=None,\n",
    "    verbose=1,\n",
    "    warm_start=True,\n",
    "    class_weight=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1\n",
      "chunk 2\n",
      "chunk 3\n",
      "chunk 4\n",
      "chunk 5\n",
      "chunk 6\n",
      "chunk 7\n",
      "chunk 8\n",
      "chunk 9\n",
      "chunk 10\n",
      "chunk 11\n",
      "chunk 12\n",
      "Model fitting finished after 0 s wall clock time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "/home/hh/anaconda3/envs/geo/lib/python3.6/site-packages/sklearn/ensemble/forest.py:305: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    }
   ],
   "source": [
    "# for now, divide large of data into smaller chunks of chunk_size samples and loop over these\n",
    "chunk_size = 1e5\n",
    "chunk_idx = np.int32(np.linspace(0, arr_x.shape[0], arr_x.shape[0]//int(chunk_size)))\n",
    "t1 = time.time()\n",
    "for i in range(len(chunk_idx)-1):\n",
    "    print(\"chunk {}\".format(i+1))\n",
    "    mdl.fit(arr_x[chunk_idx[i]:chunk_idx[i+1],:], arr_y[chunk_idx[i]:chunk_idx[i+1]])\n",
    "    \n",
    "t2 = time.time()\n",
    "print(\"Model fitting finished after {0:0.0f} s wall clock time\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36658345, 0.08498371, 0.15107657, 0.1287924 , 0.06574827,\n",
       "       0.03611766, 0.11949418, 0.03025478, 0.01694899])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/RandomForest_binary.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "joblib.dump(mdl, trained_model_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hh/anaconda3/envs/geo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xix1, xix2 = 0, 1\n",
    "f,axs = plt.subplots(2,2)\n",
    "axs[0,0].imshow(x[:,:,:3])\n",
    "axs[0,1].imshow(y, cmap=\"gray\")\n",
    "axs[1,0].scatter(x[y==200,xix1], x[y==200,xix2])\n",
    "axs[1,1].scatter(arr_x[arr_y==200,xix1], arr_x[arr_y==200,xix2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
