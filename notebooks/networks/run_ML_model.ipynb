{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from keras.layers import merge\n",
    "from src.data import utils\n",
    "from src.models.data import *\n",
    "from src.models.model import *\n",
    "from src.models.predict_model import *\n",
    "from src.data.utils import get_tile_prefix\n",
    "\n",
    "#from rasterio.plot import show, reshape_as_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import signal\n",
    "\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import sys\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to append\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/media/hh/hd_internal/hh/DSR_Berlin_2018/roaddetection/\")\n",
    "\n",
    "# base directories with data (image tiles) to be analyzed\n",
    "base_dir = \"../../data\"\n",
    "dirs = []\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validate\")\n",
    "dirs.append(validation_dir)\n",
    "# subdirs\n",
    "dir_x = 'sat'\n",
    "dir_y = 'map'\n",
    "\n",
    "# max. number of samples (files) to analyze\n",
    "max_num_x = 3\n",
    "\n",
    "# ------------- image characteristics -----------------------------\n",
    "# size of tiles\n",
    "target_size = (512,512)\n",
    "\n",
    "\n",
    "#--------------- model ----------------------------------------------------\n",
    "# set to True if a binary model shall be run\n",
    "model_is_binary = True\n",
    "# path to & filename of model to save\n",
    "trained_model_fn = '../../models/RandomForest_binary.pkl'\n",
    "if True:\n",
    "    # set to True if a binary model shall be run\n",
    "    model_is_binary = False\n",
    "    # path to & filename of model to save\n",
    "    trained_model_fn = '../../models/RandomForest_multiclass.pkl'\n",
    "\n",
    "#--------------- training details / hyperparameters -----------------------------------\n",
    "\n",
    "# graphics defaults\n",
    "figsize = (20,12)\n",
    "plt.rcParams[\"figure.figsize\"] = figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain list and number of available samples (files)\n",
    "file_list_x, num_x = utils.get_list_samplefiles(os.path.join(train_dir, dir_x))\n",
    "\n",
    "# actual number of samples that will be used for training, given samples available and user's choice\n",
    "num_x_use = min(num_x, max_num_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    criterion='gini',\n",
    "    max_depth=5,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=20,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=None,\n",
    "    verbose=1,\n",
    "    warm_start=False,\n",
    "    class_weight=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrices to be used for convolution\n",
    "def conv_matrix_inhibsurround():\n",
    "    \"\"\"\n",
    "    3 by 3, positive center, negative surround\n",
    "    Elements sum to zero\n",
    "    \"\"\"\n",
    "    m = np.ones((3, 3), dtype=np.float32) / -8.0\n",
    "    m[1, 1] = 1.0\n",
    "    return m\n",
    "\n",
    "def conv_matrix_horizontalbar():\n",
    "    \"\"\"\n",
    "    3 by 3, positive center row, negative surround\n",
    "    Elements sum to zero\n",
    "    \"\"\"\n",
    "    m = np.ones((3, 3), dtype=np.float32) / -6.0\n",
    "    m[1, :] = 1.0/3.0\n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CLASS_DICT = get_class_dict()\n",
    "# \n",
    "num_features = 4\n",
    "# number of pixels per image\n",
    "img_size = np.prod(target_size)\n",
    "# preallocate arrays collecting features (x) and labels (y) of all samples\n",
    "arr_x = np.empty((img_size * num_x_use, num_features), dtype=np.float32)\n",
    "arr_y = np.empty(img_size * num_x_use, dtype=np.uint8)\n",
    "\n",
    "m_inhibsurround = conv_matrix_inhibsurround()\n",
    "m_horizontalbar = conv_matrix_horizontalbar()\n",
    "\n",
    "\n",
    "for i, fn in enumerate(file_list_x[:num_x_use]):\n",
    "    # read sat image tile\n",
    "    x = io.imread(os.path.join(train_dir, dir_x, fn))\n",
    "    print(x.dtype)\n",
    "    # feature engineering\n",
    "    x_filt = feature_eng_conv(x, m_horizontalbar, collapse_bands=True)\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    fig.figsize=(20,20)\n",
    "    axs[0].imshow(x[:,:,:3])\n",
    "    #axs[1].imshow(x_filt[:,:,3])\n",
    "    axs[1].imshow(x_filt, cmap=\"gray\")\n",
    "\n",
    "    \n",
    "    # read corresponding label tile\n",
    "    y = io.imread(os.path.join(train_dir, dir_y, fn))  \n",
    "    # refactor labels\n",
    "    y, mask = refactor_labels(x, y, class_dict=CLASS_DICT, model_is_binary=model_is_binary, meta=None)\n",
    "    # scale x\n",
    "    x = x/255.0\n",
    "    print(\"{0:s}: ({1:0.0f} % non-image pixels)...\".format(fn, 100*np.sum(mask)/img_size))\n",
    "    # copy flattened features and labels in arrays\n",
    "    arr_y[i*img_size:(i+1)*img_size] = y.reshape(img_size, order = 'C')\n",
    "    arr_x[i*img_size:(i+1)*img_size,:] =x.reshape((img_size, num_features), order = 'C')\n",
    "    \n",
    "# retain all except no_img values\n",
    "good_ix = arr_y != CLASS_DICT[\"no_img\"]\n",
    "arr_x = arr_x[good_ix, :]\n",
    "arr_y = arr_y[good_ix]\n",
    "print(\"{} classes present in data\".format(len(np.unique(arr_y))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "mdl.fit(arr_x, arr_y)\n",
    "t2 = time.time()\n",
    "print(\"Model fitting finished after {0:0.0f} s wall clock time\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(mdl, trained_model_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "arr_x_plot = arr_x[::100,:]\n",
    "arr_y_plot = arr_y[::100]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ix = arr_y_plot == 40\n",
    "ax.scatter(arr_x_plot[ix,0], arr_x_plot[ix,1], arr_x_plot[ix,3], c=\"gray\", alpha=0.05)  # , c=c, marker=m\n",
    "ix = arr_y_plot == 200\n",
    "ax.scatter(arr_x_plot[ix,0], arr_x_plot[ix,1], arr_x_plot[ix,3], c=\"red\")  # , c=c, marker=m\n",
    "\n",
    "\n",
    "ax.set_xlabel('B')\n",
    "ax.set_ylabel('G')\n",
    "ax.set_zlabel('IR')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
