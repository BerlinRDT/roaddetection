{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/roaddetection/\")\n",
    "sys.path.append(\"/mnt/hd_internal/hh/projects_DS/road_detection/roaddetection\")\n",
    "from src.models.data import trainGenerator\n",
    "from src.models.network_models import unet, unet_var\n",
    "from src.data.utils import get_tile_prefix\n",
    "from src.models.metrics_img import auc_pr\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, LambdaCallback\n",
    "from keras.optimizers import Adam\n",
    "#from pathlib import Path\n",
    "import os, shutil, platform\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = []\n",
    "data_dir = \"../../data\"\n",
    "model_dir = \"../../models/UNet\"\n",
    "report_dir = \"../../reports\"\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "\n",
    "train_partial_dir = os.path.join(data_dir, \"train_partial\")\n",
    "dirs.append(train_partial_dir)\n",
    "\n",
    "validation_dir = os.path.join(data_dir, \"validate\")\n",
    "dirs.append(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "dirs.append(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- image characteristics and augmentation -----------------------------\n",
    "# size of tiles\n",
    "target_size = (512,512)\n",
    "# input arguments to Keras' ImageDataGenerator\n",
    "data_gen_args = dict(\n",
    "                    data_format=\"channels_last\",\n",
    "                    horizontal_flip=True, \n",
    "                    vertical_flip=True\n",
    " )\n",
    "# directory into which to place *training* images from ImageDataGenerator for inspection;\n",
    "# default should be None because this slows things down\n",
    "imgdatagen_dir = None\n",
    "#imgdatagen_dir = data_dir + '/imgdatagenerator'\n",
    "\n",
    "#--------------- network weights ----------------------------------------------------\n",
    "# path to & filename of pre-trained model to use - set to None if you want to start from scratch\n",
    "pretrained_model_fn = model_dir + '/models_unet_borneo_and_harz_05_09_16_22.hdf5'\n",
    "pretrained_model_fn = model_dir + '/unet_var_test.hdf5'\n",
    "pretrained_model_fn = None\n",
    "\n",
    "# path to & filename of model to save\n",
    "trained_model_fn = model_dir + '/unet_test.hdf5'\n",
    "\n",
    "#--------------- training details / hyperparameters -----------------------------------\n",
    "# batch size\n",
    "batch_size = 1\n",
    "# steps per epoch, should correspond to [number of training images] / batch size\n",
    "steps_per_epoch = 600 // batch_size\n",
    "# number of epochs\n",
    "epochs = 10\n",
    "# number of steps on validation set\n",
    "validation_steps = 60\n",
    "# self-explanatory variables:\n",
    "optimizer = Adam(lr=2e-4)\n",
    "loss = 'binary_crossentropy'\n",
    "loss_weights = None\n",
    "metrics = ['accuracy', auc_pr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count image tiles in train/validation/test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in dirs:\n",
    "    for file_type in [\"sat\", \"map\", \"sat_rgb\"]:\n",
    "        target = os.path.join(directory, file_type)\n",
    "        print(target, \":\", len(os.listdir(target)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ImageDataGenerators for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = trainGenerator(batch_size, data_dir + '/train_partial','sat','map',\n",
    "                        data_gen_args, save_to_dir = imgdatagen_dir, image_color_mode=\"rgba\", target_size=target_size)\n",
    "\n",
    "validation_gen = trainGenerator(batch_size, data_dir + '/validate','sat','map',\n",
    "                        data_gen_args, save_to_dir = None, image_color_mode=\"rgba\", target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model, compile, show summary, possibly load weights, define callbacks (including checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_var()\n",
    "#model = unet()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              loss_weights=loss_weights,\n",
    "              metrics=metrics)\n",
    "model.summary()\n",
    "if (pretrained_model_fn):\n",
    "    model.load_weights(pretrained_model_fn)\n",
    "model_checkpoint = ModelCheckpoint(trained_model_fn, monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "#Stop training if loss doesn't improve for 2 consecutive epochs\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_logger():\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "    formatter = logging.Formatter(log_fmt)\n",
    "    fh = logging.FileHandler('../../logs/unet-2.log')\n",
    "    fh.setFormatter(formatter)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.addHandler(fh)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "logging_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: logger.info({'epoch': epoch, 'logs': logs})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              callbacks=[model_checkpoint, early_stop, logging_callback],\n",
    "                              validation_data=validation_gen,\n",
    "                              validation_steps=validation_steps\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history[\"acc\"], label=\"acc\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(history[\"auc_pr\"], label=\"auc_pr\")\n",
    "    plt.plot(history[\"val_auc_pr\"], label=\"val_auc_pr\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(\"../../logs/unet_borneo_and_harz_05_09_11_11.jpg\")\n",
    "    plt.close()\n",
    "\n",
    "plot_history(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
